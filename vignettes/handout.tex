\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Handout to the R package `divDyn' v0.4.1 for diversity dynamics from fossil occurrence data},
            pdfauthor={Adam T. Kocsis, Carl J. Reddin, Wolfgang Kiessling},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Handout to the R package `divDyn' v0.4.1 for diversity dynamics from
fossil occurrence data}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Adam T. Kocsis, Carl J. Reddin, Wolfgang Kiessling}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-07-07}


\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{1. Introduction}\label{introduction}}

The purpose of this vignette is to guide users through the basic
capabilities of the `divDyn' package. Fossil occurrence databases, such
as the Paleobiology Database (PaleoDB, \url{http://www.paleobiodb.org/},
\url{http://fossilworks.org}) are readily available to be used in
analyses of diversity, extinction and origination patterns (the dynamics
of biodiversity), with a certain set of toolkit that has become standard
since the creation of the database. Until now, the implementation of
most of these tools have been the responsibilities of individual
researchers, with no software package to rely on. This R package intends
to fill this gap.

\hypertarget{installation}{%
\subsection{1.1. Installation}\label{installation}}

In order to install this beta version of the package, you have to
download it from GitHub
(\url{http://www.github.com/adamkocsis/divDyn/}). The installation
instructions will be found on this webpage, but the package is planned
to be uploaded to the CRAN servers as well. All questions should be
addressed to Adam Kocsis, the creator and maintainer of the package
(\href{mailto:adam.kocsis@fau.de}{\nolinkurl{adam.kocsis@fau.de}}).

\hypertarget{necessary-data}{%
\section{2. Necessary Data}\label{necessary-data}}

All functions in the `divDyn' package are built on two fundamental data
structures: a time scale table and an occurrence dataset.

\hypertarget{time-scales}{%
\subsection{2.1. Time scales}\label{time-scales}}

The workflow presented here is based on the discretization of geological
time, which is constrained by stratigraphy. These intervals of time
(bins) represent the basic units of the analysis, and their sequence is
coded in the time scale table. Even if we develop a geological model
that outputs robust estimates in a continuous time axis, the calculation
of metrics presented in the package will require discretization. We
added implementations of the basic functionalities for continuous time
(chapter `4.3. Slicing') as well, but we do not deem it as reliable as
using stratigraphic bins for million-year-scale, deep-time analyses. As
age estimates are dependent on the different time scales, binning the
data can change more than necessary, which can have random effects on
the resulting series. In order to demonstrate the workflow of binned
analyses, we added an example table to the package. This table
represents a somewhat altered form of the stage-level geological time
scale of Gradstein et al. (2012). You can attach this table using the
\texttt{data()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(divDyn)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# attach the time scale object}
\KeywordTok{data}\NormalTok{(stages)}
\end{Highlighting}
\end{Shaded}

Every row in this table represents a bin in the timescale. The most
important variable in this table is the slice number (in this case
\texttt{num}). This variable links every occurrence to one of the bins.
You can gather additional information by typing \texttt{?stages} to the
console. You can visualize the timescale by using the \texttt{plots()}
function included in the package:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{shading=} \StringTok{"series"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/plotTS1-1.pdf}

For easier navigation in the plot, the time dimension can be indicated
with three variables: the radiometric dates, that serve as coordinates;
boxes of intervals under lowest \texttt{ylim} value of the plot; and
vertical shades over the plotting area. The time scale to be plotted can
be altered by changing the values of the main argument \texttt{tsdat}
and by providing the appropriate column names for the boxes and shading
arguments. In order to use the period names as labels and the stages as
shades, just change the function input accordingly (the \texttt{xlim}
values will limit the x axis plot):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"period"}\NormalTok{, }\DataTypeTok{shading=}\StringTok{"stage"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{59}\OperatorTok{:}\DecValTok{81}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/plotTS2-1.pdf}

The function was designed to enable the highest level of customization.
You can customize the distribution of plotting area with the
\texttt{xlim} (accepts exact ages and sequences of bins, see the
examples), \texttt{ylim}, \texttt{prop} and \texttt{gap} arguments, and
the color of the shading. You can also customize the characteristics of
the general plotting (calling \texttt{plot()}, the boxes of time slices
(calling \texttt{rect()}) and the labels within them (calling the
\texttt{text()} function). You can directly control the arguments of
these functions that \texttt{plotTS()} uses to draw the elements of the
timescale by adding the additional arguments as lists to the
\texttt{plot.args}, \texttt{boxes.args} and \texttt{labels.args}
arguments.\\
For instance, if you want your boxes to feature red italic fonts as
labels, just add col=``red'', and font=3 the way you would regularly use
them with the text() function, but wrap them up in a list, and assign it
to the `labels.args' argument:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }
  \DataTypeTok{labels.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{font=}\DecValTok{3}\NormalTok{), }\DataTypeTok{shading.col=}\KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{, }\StringTok{"wheat"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/plotTS3-1.pdf}

Naturally, you can use other time scale plotting packages such as the
`geoscale' package developed by J. Bell (2015). These work great for
Phanerozoic scale analyses, but be sure to check the compatibility of
the time scale you use for the binning and the time scale used for
plotting. As we have experience with problems that stemmed from the
incompatibility of analyzing and plotting data, we recommend using your
own timescale for plotting.

\hypertarget{occurrence-table}{%
\subsection{2.2. Occurrence table}\label{occurrence-table}}

The occurrence tables contain unary information about the presence of
taxon at a specified locality (can be global). In these tables, each
occurrence is represented a row which has to include a name of the
taxon. The functions of the package will have to be pointed to this
column, by specifying its name in the \texttt{tax} argument of the
function in question. Additional variables can be added that contain
specific information about the time and locality of the occurrence, as
well as other variables that help with grouping the individual entries
(taxon/collection information). The utility of this long format is in
its unbounded nature, with the acquisition of newer data points the time
and spatial coverage of the dataset can extend without problems.

\hypertarget{stratigraphic-assignment}{%
\subsubsection{2.2.1. Stratigraphic
assignment}\label{stratigraphic-assignment}}

Most functions rely on processes that subset the data to contain
occurrences that represent the same time interval. This column can be
specified with setting the \texttt{bin} argument accordingly. However,
to get this column, a number of processes has to be run on the raw data.
Although the package already incorporates functions to and data to
assign downloaded occurrences to stratigraphic bins, those will be
illustrated in a separate handout.

\hypertarget{the-example-file}{%
\subsubsection{2.2.2. The example file}\label{the-example-file}}

In order to demonstrate most capabilities of the package we have added a
fossil occurrence table of Scleractinian corals that we used in an
earlier study (Kiessling and Kocsis, 2015). This subset was downloaded
from the PaleoDB and was extended with information on inferred
photosymbiotic status, growth types, degree of integration, ecological
environment, inferred depth, substrate lithology and latitudinal groups.
Additional details are available by typing \texttt{?corals} to the
console. This dataset is embedded in the package and can be attached
using the data() function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(corals)}
\end{Highlighting}
\end{Shaded}

This dataset was resolved to the 10 my timescale of the PaleoDB
(\texttt{BIN}, now only available through FossilWorks) and the more or
less stage level time scale (variable \texttt{slc}) that is included in
the package (\texttt{stages}). This latter is the basis of all inference
and plotting. The values of the \texttt{slc} column of the coral table
refers to entries in the \texttt{num} column of the \texttt{stages}
table. Please note that this dataset does not include Holocene
occurrences. The occurrences designated with \texttt{slc==95} are just
single entries that include extant genera; therefore all other entries
of this subset are missing, except for the variables linked to the taxa.
The rest of the occurrences represent actual fossils.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils <-}\StringTok{ }\NormalTok{corals[corals}\OperatorTok{$}\NormalTok{slc}\OperatorTok{!=}\DecValTok{95}\NormalTok{,]}
\CommentTok{# the number of occurrences}
\KeywordTok{nrow}\NormalTok{(fossils)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29544
\end{verbatim}

\hypertarget{basic-patterns}{%
\section{3. Basic patterns}\label{basic-patterns}}

\hypertarget{ranges}{%
\subsection{3.1. Ranges}\label{ranges}}

We can gain preliminary knowledge by examining the basic patterns of the
stratigraphic ranges . Probably the most apparent of these are the
stratigraphic ranges of the taxa, which can be easily summarized in the
FAD-LAD matrix:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fl <-}\StringTok{ }\KeywordTok{fadLad}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

and the survivorship curves. The function \texttt{survivors()}
calculates the proportions of survivors from every bin to all the
remaining bins.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surv <-}\StringTok{ }\KeywordTok{survivors}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can plot these values for every cohort to get survivorship curves.
As these curves can be thought of as products of an exponential decay,
it is customary to log the y axis, which you can do with adding
\texttt{log="y"} to the arguments of the main \texttt{plot()} function
in \texttt{plot.args}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# time scale plot}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }
  \DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{260}\NormalTok{,}\DecValTok{0}\NormalTok{), }\DataTypeTok{ylab=}\StringTok{"proportion of survivors present"}\NormalTok{,}
  \DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{plot.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{log=}\StringTok{"y"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/survPlotTSblank-1.pdf}

Then the curves can be plotted for every column with

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# lines for every cohort}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(surv)) }\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid, surv[,i])}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/survPlotTS1-1.pdf}

The values shown here are also called `forward' survivorship
proportions, but you can also plot the `backward' survivorships to see
how certain cohorts emerge over geologic time, by setting the
\texttt{method} argument appropriately:

\includegraphics{handout_files/figure-latex/survPlotTS2-1.pdf}

Large synchronous changes in these curves represent times where major
changes happened in the history of the group. Major extinctions are
apparent on the forward survivorship, whilst major origination episodes
show up on the backward survivorship curves. However, ways that are more
robust exist to quantify the factors that influence diversity.

\hypertarget{sampling-parameters}{%
\subsection{3.2. Sampling parameters}\label{sampling-parameters}}

\hypertarget{basic-descriptors}{%
\subsubsection{3.2.1. Basic descriptors}\label{basic-descriptors}}

The patterns of the data are constrained by sampling processes. These
can have a direct influence on the patterns of diversity dynamics and
therefore should be taken into consideration, when the conclusions are
drawn from the data. You can calculate the basic sampling
characteristics with the \texttt{sampstat()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp <-}\KeywordTok{sampstat}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }
  \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## The database contains duplicate occurrences (multiple species/genus).
\end{verbatim}

The message above indicates that multiple entries of the same genus are
present in the same collections. As this is a species-level occurrence
dataset, this is understandable. By default, these entries are omitted
from the calculations above, but you can toggle this manually by setting
the \texttt{duplicates} argument of the function accordingly
(\texttt{TRUE} will keep the duplicates, \texttt{FALSE} will omit them
â€`` without notification). With the default settings the function
(\texttt{total=FALSE}) calculates the basic binwise statistics that do
not require multi-bin pattern recognition (for instance for Alroy's
(2008) three-timer sampling completeness, which is output by the
\texttt{divDyn()} function). These can be plotted then in a
straightforward way, by referring to the elements of the data frame. For
instance, the \texttt{occs} element contains the number of sampled
occurrences and, \texttt{coll} refers to the number of collections:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar=}\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\CommentTok{# basic plot}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], samp}\OperatorTok{$}\NormalTok{occs)}
\CommentTok{# the collections (rescaled, other axis)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], samp}\OperatorTok{$}\NormalTok{colls}\OperatorTok{*}\DecValTok{5}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
  \KeywordTok{axis}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{,}\DataTypeTok{col.ticks=}\StringTok{"blue"}\NormalTok{,}\DataTypeTok{col.axis=}\StringTok{"blue"}\NormalTok{,}
    \DataTypeTok{at=}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{,}\DecValTok{500}\NormalTok{), }\DataTypeTok{labels=}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{600}\NormalTok{,}\DecValTok{100}\NormalTok{))}
  \KeywordTok{mtext}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DataTypeTok{text=}\StringTok{"number of collections"}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{line=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/occsAndColls-1.pdf}

The \texttt{sampstat()} function also calculates other basic statistics
such as the numbers of references, sampled taxa, single-collection taxa,
single-reference taxa, double collection and double reference taxa along
with the sampling coverage estimator Good's \emph{u} (1953), the
coverage estimator suggested by Alroy (\emph{u' }, 2010) that is based
on the number of single-reference taxa. Setting the \texttt{total}
argument to \texttt{TRUE} will output the statistics of the total
dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp <-}\KeywordTok{sampstat}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }
  \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{, }\DataTypeTok{total=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{samp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   bins  occs taxa colls refs gappiness
## 1   41 23229  760  5444 1203 0.5818335
\end{verbatim}

This includes the total number of occurrences, collections, references
and statistics of gappiness.

\hypertarget{plotting-of-counts-and-proportions}{%
\subsubsection{3.2.2. Plotting of counts and
proportions}\label{plotting-of-counts-and-proportions}}

You can trace the trajectory of the occurrences that have different
attributes through the bins by using the \texttt{parts()} function. This
requires only two arguments: vector of bin identifiers and a vector that
contains the categories entries. The bin identifier also determines the
coordinates along the independent variable (time), so the numerical bin
entries have to be replaced by the age estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# numerical ages, as bins}
\NormalTok{fossils}\OperatorTok{$}\NormalTok{slcMid <-}\StringTok{ }\NormalTok{stages}\OperatorTok{$}\NormalTok{mid[fossils}\OperatorTok{$}\NormalTok{slc]}
\CommentTok{#plotting}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"number of occurences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{))}
\KeywordTok{parts}\NormalTok{(fossils}\OperatorTok{$}\NormalTok{slcMid, fossils}\OperatorTok{$}\NormalTok{bath)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/parts-1.pdf}

If you check out \texttt{?parts}, there will be additional examples
using artificial data. In the default case, the category names are
plotted where they are the most abundant. This plot can be even nicer if
you use opacity (RGBA values for colors) and adding a proper legend.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cols <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"#FF0000AA"}\NormalTok{, }\StringTok{"#00FF00AA"}\NormalTok{, }\StringTok{"#0000FFAA"}\NormalTok{)}
\CommentTok{# reorder too}
\NormalTok{reord <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"shal"}\NormalTok{,}\StringTok{"deep"}\NormalTok{,}\StringTok{"uk"}\NormalTok{)}
\NormalTok{plotnames <-}\KeywordTok{c}\NormalTok{(}\StringTok{"shallow"}\NormalTok{, }\StringTok{"deep"}\NormalTok{, }\StringTok{"unknown"}\NormalTok{)}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"the number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{))}
\KeywordTok{parts}\NormalTok{(fossils}\OperatorTok{$}\NormalTok{slcMid, fossils}\OperatorTok{$}\NormalTok{bath, }\DataTypeTok{col=}\NormalTok{cols, }\DataTypeTok{ord=}\NormalTok{reord, }\DataTypeTok{labs=}\NormalTok{F)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{inset=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.01}\NormalTok{), }
  \DataTypeTok{legend=}\NormalTok{ plotnames, }\DataTypeTok{fill=}\NormalTok{cols, }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/parts2-1.pdf}

The dominance of shallow occurrences are even more apparent with
proportions. You can use the \texttt{parts} function to plot these,
rather than the counts, by adding \texttt{prop=T} to the function call:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"proportion of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{parts}\NormalTok{(fossils}\OperatorTok{$}\NormalTok{slcMid, fossils}\OperatorTok{$}\NormalTok{bath, }\DataTypeTok{prop=}\NormalTok{T, }\DataTypeTok{col=}\NormalTok{cols, }\DataTypeTok{ord=}\NormalTok{reord, }\DataTypeTok{labs=}\NormalTok{F)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"bottomleft"}\NormalTok{, }\DataTypeTok{inset=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }
  \DataTypeTok{legend=}\NormalTok{ plotnames, }\DataTypeTok{fill=}\NormalTok{cols, }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/parts3-1.pdf}

\hypertarget{single-collection-and-single-reference-taxa}{%
\subsubsection{3.2.3. Single-collection and single reference
taxa}\label{single-collection-and-single-reference-taxa}}

Single-interval taxa were thought to be byproducts of temporary
increases of sampling intensity (Foote and Raup, 1996) in range-based
datasets such as Sepkoski's compendium (2002). This phenomenon urged
researchers to develop metrics that ignore these taxa in calculating
metrics of biodiversity and evolution. Single-collection taxa can be
quickly omitted from the datasets by using the \texttt{omit()} function.
This will return a logical vector, indicating the rows that should be
omitted. The \texttt{om} argument can be set either to omit the
single-collection occurrences (\texttt{om="coll"}). Single-reference
taxa can be omitted in the same way, although the term needs additional
clarification, when viewed from the angle, where multiple bins exist.
Taxa that were only described in a single reference (\texttt{om="ref"}).
Some taxa appear in multiple bins and in each of them they are described
by only one reference. These you can omit with \texttt{om="binref"}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{omitColl <-}\StringTok{ }\KeywordTok{omit}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{om=}\StringTok{"coll"}\NormalTok{)}
\NormalTok{omitRef <-}\StringTok{ }\KeywordTok{omit}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{om=}\StringTok{"ref"}\NormalTok{)}
\NormalTok{omitBinref <-}\StringTok{ }\KeywordTok{omit}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{om=}\StringTok{"binref"}\NormalTok{)}
\CommentTok{# the conserved number of occurrences will be}
\KeywordTok{sum}\NormalTok{(}\OperatorTok{!}\NormalTok{omitColl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29583
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(}\OperatorTok{!}\NormalTok{omitRef)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29489
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(}\OperatorTok{!}\NormalTok{omitBinref)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29105
\end{verbatim}

\hypertarget{raw-diversity-dynamics}{%
\section{4. Raw diversity dynamics}\label{raw-diversity-dynamics}}

The main calculations of the package are contained in the
\texttt{divDyn()} function. This function calculates patterns of taxon
occurrences and stratigraphic ranges to derive estimates over time for
richness, origination/extinction rates and sampling probabilities. In
order to make calculate these you only need an occurrence table with
variables including the taxon names (\texttt{tax}) and the time
identifiers (\texttt{bin}). The rest of the information in the table
will not be used by the function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ddFirst<-}\KeywordTok{divDyn}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{noNAStart=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The output of the \texttt{divDyn()} function is a \texttt{data.frame}
class object that contains values for each bins in rows. The first
column (\texttt{bin} variable) contains the bin identifiers. The rest of
the variables are explained in the documentation.

\hypertarget{diversity-taxonomic-richness}{%
\subsection{4.1. Diversity (taxonomic
richness)}\label{diversity-taxonomic-richness}}

You read this because you have interests in the changes of diversity.
Calculating time series of diversity does not require additional action
than running the basic \texttt{divDyn()} function.

\hypertarget{taxon-counts}{%
\subsubsection{4.1.1.Taxon counts}\label{taxon-counts}}

All calculations in this function depend on patterns of occurrences in
the bin/taxon matrix. The numbers of taxa that belong to different
categories form the basis of the metrics. These categories are explained
by Foote (2000) and Alroy (2014) and are available in the help file
\texttt{?divDyn}.

\hypertarget{different-metrics-of-richness}{%
\subsubsection{4.1.2. Different metrics of
richness}\label{different-metrics-of-richness}}

Calculating time series of diversity does not require additional action
than running the basic \texttt{divDyn()} function. In this package,
among the traditional range-based methods the range-through (variable
\texttt{divRT}) and the boundary-crosser (\texttt{divBC}) diversities
are implemented. Plotting can be also facilitated by matching the
indices of the diversity values in the variables and their numbers. If
the bin numbers are positive integers this is turned on by setting the
\texttt{noNAStart} argument to \texttt{FALSE}, which is the default.
This change results in \texttt{NA}s and zeros in the final table in
rows, which bins are not sampled.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# metrics}
\NormalTok{ddRec <-}\KeywordTok{divDyn}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"range-through richness (diversity)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
\CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid, ddRec}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddRec-1.pdf}

This plot shows the trajectory of coral diversity over the post-Permian
interval, using raw data and the range-through diversity metric. You
might notice a sharp increase of richness in the latest intervals. This
could be the result of an effect called the `Pull of the Recent'. The
`Pull of the Recent' (Raup, 1979) is a smearing phenomenon that arises
when range-based methods are calculated from datasets where sampling
probability changes abruptly. As we know the recent much better in
comparison to other intervals (sampling probability is much higher,
around one), the number of ranges that connect first occurrences of taxa
to the extant time interval (\texttt{slc\ ==\ 95}) is much higher than
those that link two non-recent time intervals. The results in spur of
diversity as the recent is approached. On the other hand, omitting the
recent interval (effectively decreasing sampling probability to 0) leads
to edge effects that result in the opposite phenomenon. The discrepancy
between these two approaches can be visualized by the omission of the
recent `occurrences':

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# metrics}
\NormalTok{dd <-}\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"richness (diversity)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
\CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid, ddRec}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"with recent"}\NormalTok{, }\StringTok{"without recent"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddFossils-1.pdf}

Over the last couple of decades, a number of metrics were proposed to
efficiently express diversity given such distorting effects of
incomplete sampling and the discretized time dimension. As these more
straightforward approaches have known issues, occurrence datasets make
more direct, allows the calculations of sampled-in-bin (SIB, variable
\texttt{divSIB}) diversities.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# metrics}
\NormalTok{dd <-}\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"richness (diversity)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
\CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divBC, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divSIB, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"RT"}\NormalTok{, }\StringTok{"BC"}\NormalTok{, }\StringTok{"SIB"}\NormalTok{), }
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{,   }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddDiv-1.pdf}

Although the `SIB' metric is not biased range-extension, it is more
affected by sampling. The three-timer sampling completeness is an
effective expression of changes in sampling (\texttt{samp3t} variable):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"three-timer sampling completeness"}\NormalTok{)}
  \CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{samp3t, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/samp3t-1.pdf}

The SIB series can be partially corrected by the three-timer
sampling-completeness (Alroy Â§ref ). Although this can be convenient a
correction it also increases the estimation error. Nevertheless, this is
the least biased estimator for diversity.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"three-timer sampling completeness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"SIB"}\NormalTok{, }\StringTok{"corrected SIB"}\NormalTok{ ), }
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddCorr-1.pdf} The
\texttt{omit()} function is also embedded in the \texttt{divDyn()}, so
that the metrics are calculated after the omission of poorly sampled
taxa. You can add this filter, by adding (the appropriate \texttt{om}
argument and the ) \#\# 4.2. Taxonomic rates

Analyzing time series of originations and extinctions help us to
describe not just how diversity changed over time, by also why it
changed. With taxonomic rates we can decompose changes in diversity to
the relative contribution of cladogenetic processes (i.e.~origination,
the birth of a new taxon) and that of the disappearance of taxa
(i.e.~extinction, the death of a taxon). In the discrete time model, the
most straightforward way to express these contributions is through
simple exponential decay models (Raup, 1985). For convenience, these
variables are named as \texttt{ext...} and \texttt{oriâ€¦} for
extinction and origination rates, respectively.

\hypertarget{different-metrics-of-turnover}{%
\subsubsection{4.2.1. Different metrics of
turnover}\label{different-metrics-of-turnover}}

In the package, the proportional rates (\texttt{extProp} and
\texttt{oriProp}) per capita rates (\texttt{extPC} and \texttt{oriPC})
of Foote (2000), the three-timer rates (\texttt{ext3t} and
\texttt{ori3t}) of Alroy (2008), their corrected counterparts
(\texttt{extC3t} and \texttt{oriC3t}), the gap-filler rates
(\texttt{extGF} and \texttt{oriGF}) of Alroy (2014) and the improved
second-for-third (\texttt{ext2f3} and \texttt{ori2f3}) of Alroy (2015).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"extinction rates"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{extPC, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{extGF, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{ext2f3, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"per capita"}\NormalTok{, }\StringTok{"gap-filler"}\NormalTok{, }\StringTok{"second-for-third"}\NormalTok{),}
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddExt-1.pdf}

The documentation of the function (type in console ?divDyn) contains the
formulas for the calculation of the rates. With heterogeneous,
incomplete sampling the metrics have different properties that can be
summarized as follows:

\begin{itemize}
\item
  Proportional `rates': These metrics express what proportion of the
  cohort of taxa disappears until the new interval.
\item
  The per capita rates of Foote (2000) use the range-through assumption
  to establish ranges for the taxa in the dataset. The rate value
  expresses what proportion of the taxa decayed until the end of the
  interval. The method is biased by the Signor-Lipps effect and edge
  effects.
\item
  The `three-timer' and `corrected three-timer' rates (Alroy, 2008) are
  different estimators of the per capita rates but will converge on them
  when sampling tends to completeness. They use moving windows around
  the focal interval to select data that is more relevant to the focal
  interval. This metric is unbiased by the Signor-Lipps and edge
  effects. The three-timer sampling completeness can be used as
  corrections to this metric, but it will not improve its susceptibility
  to random sampling error.
\item
  The `gap-filler' rates (Alroy, 2014): gap-filler extinction rates are
  improved versions of the three-timer rates, using a four bin moving
  windows instead of three. This makes the rates less resistant to
  random error and an improvement on the three-timer rates. The method
  sometimes results in the seemingly nonsensical negative extinction
  rates, when the true extinction rates are near 0.
\item
  The `second-for-third' rates (Alroy, 2015) are further improvement of
  ideas the three-timer and gap-filler rates represent. By adding an
  algorithmic approach the frequency of negative extinction rates are
  even further decreased. Extinction and origination proportions
  described by Alroy (2015) can also be used (\texttt{E2f3} and
  \texttt{O2f3}).
\end{itemize}

\hypertarget{selectivity-testing-for-the-per-capita-rates}{%
\subsubsection{4.2.2. Selectivity testing for the per capita
rates}\label{selectivity-testing-for-the-per-capita-rates}}

Although extinction and origination rates can provide information about
events and background processes on their own, sometimes it is more
useful to assess them in comparison between taxa. The most frequent way
of doing this is by splitting a group to subsets and compare the
patterns of turnover in certain intervals. In the case of selectivity
testing, an ecologically, taxonomically important variable indicates
that one of the groups should have higher turnover at a specific point
in time. For the sake of convenience in hypothesis testing for
selectivity for one state of the variable, the available methods assess
selectivity between two groups.

The general problem of extinction selectivity is the error estimation of
the rate values. More data (e.g.~more taxa) will lead to more reliable
estimates while, splitting the same dataset to two subsets will lead to
higher uncertainty in the rate estimates for the two rate values in the
selected interval. The selectivity testing incorporate two aspects: (1)
the difference between the two rate values, (2) and whether this
distance is meaningful or not. In practice, these two criteria can be
summarized by whether it is more supported by the data to talk about two
rate values, or is it more founded to talk about just one. These two
alternative are sometimes called as \emph{single-rate model} and the
\emph{dual-rate model} (Kiessling and Simpson, 2011; Kiessling and
Kocsis, 2015). In case a dual rate model is supported more, that means
that the difference between the two values of rates is statistically
meaningful, and the extinction or origination event selectively affected
the group with the higher value. For example here are the raw
origination rates of corals, plotted for the \emph{az} and the \emph{z}
group separately and together:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# split by ecology}
\NormalTok{  z<-}\StringTok{ }\NormalTok{fossils[fossils}\OperatorTok{$}\NormalTok{ecology}\OperatorTok{==}\StringTok{"z"}\NormalTok{,]}
\NormalTok{  az<-}\StringTok{ }\NormalTok{fossils[fossils}\OperatorTok{$}\NormalTok{ecology}\OperatorTok{==}\StringTok{"az"}\NormalTok{,]}

\CommentTok{# calculate diversity dynamics}
\NormalTok{  ddZ<-}\KeywordTok{divDyn}\NormalTok{(z, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{)}
\NormalTok{  ddAZ<-}\KeywordTok{divDyn}\NormalTok{(az, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{)}

\CommentTok{# origination rate plot}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{54}\OperatorTok{:}\DecValTok{95}\NormalTok{, }
  \DataTypeTok{ylab=}\StringTok{"raw per capita originations"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{oriPC, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{1}\NormalTok{, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], ddZ}\OperatorTok{$}\NormalTok{oriPC, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{1}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], ddAZ}\OperatorTok{$}\NormalTok{oriPC, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{2}\NormalTok{, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\DataTypeTok{inset=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.1}\NormalTok{), }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"total"}\NormalTok{, }\StringTok{"z"}\NormalTok{, }\StringTok{"az"}\NormalTok{), }
  \DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/selPrim-1.pdf}

The question that arises in this case is whether some interval can be
characterized by actually higher origination rates (for \emph{az} taxa
in the Cretaceous), or is this just a sampling artifact. The testing
framework is implemented currently only for the per capita extinction
rates of Foote (2000) in the \texttt{ratesplit} function. The function
will take the occurrence dataset as an argument and will calculate the
rates values similarly to the \texttt{divDyn} function. The function
requires a separator variable for the selection testing (\texttt{sel})
that will be used for splitting the dataset into two (this column has to
have two types of entries). The implementation of the process for the
symbiotic status is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rs<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{)}
\NormalTok{rs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## integer(0)
## 
## $ori
## [1] 57 59 75 81
\end{verbatim}

The default output of this function by default is a list of two vectors:
\texttt{ext} and \texttt{ori}, extinction rates and origination rates,
respectively. Each vector contains the bin numbers where the dual rate
model is better supported than the single rate model, where selectivity
is plausible. In the example above, selectivity for the extinctions is
unlikely and it is supported for bin 57 (Norian), 59 (Hettangian), 75
(Albian) and 81 (Maastrichtian). The statistical testing in this case is
based on the number of taxa and can be performed in two different ways,
set with the \texttt{method} argument. The less stringent \texttt{binom}
method implements binomial testing, with a significance value set with
the \texttt{alpha} parameter that defaults to 0.05.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rsBin95<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{method=}\StringTok{"binom"}\NormalTok{)}
\NormalTok{rsBin95}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## [1] 62
## 
## $ori
## [1] 57 59 75 79 81 83 88
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rsBin90<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{rsBin90}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## [1] 62 80
## 
## $ori
##  [1] 57 59 65 74 75 76 79 81 82 83 88
\end{verbatim}

The more conservative approach is to use model selection criteria for
the testing of support for the \emph{single } or \emph{dual rate
models}, which involves calculating Akaike Information Criteria and then
Akaike weights. This is the default method (\texttt{method=AIC}). The
\texttt{alpha} argument in this case depicts the minimum Akaike weight
that serve as a threshold for the \emph{dual rate model} to be
supported. As the ratio of these weights represent likelihood ratios, by
default it is set to 0.89 that roughly represents 8 times higher
likelihood for the \emph{dual rate model}. This can be toggled the way
it is deemed useful for the question at hand.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rsAIC0}\FloatTok{.5}\NormalTok{<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\NormalTok{rsAIC0}\FloatTok{.5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## [1] 57 66 80 81
## 
## $ori
##  [1] 57 59 65 74 75 76 81 82 83 88 91
\end{verbatim}

In the case above, the 0.5 \texttt{alpha} value indicates that the dual
rate model should be supported if it is more likely than the single rate
model.

This particular output is useful for plotting the selectivity values
that can be easily visualized by dots. You can add these to the plot of
\emph{z} and \emph{az} coral origination rates by running:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# select rate values in the intervals of selectivity}
\NormalTok{selIntervals<-}\KeywordTok{cbind}\NormalTok{(ddZ}\OperatorTok{$}\NormalTok{oriPC, ddAZ}\OperatorTok{$}\NormalTok{oriPC)[rs}\OperatorTok{$}\NormalTok{ori,]}
\CommentTok{# which is higher? TRUE: AZ, FALSE: Z}
\NormalTok{groupSelector<-}\KeywordTok{apply}\NormalTok{(selIntervals, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) x[}\DecValTok{1}\NormalTok{]}\OperatorTok{<}\NormalTok{x[}\DecValTok{2}\NormalTok{])}
\CommentTok{# draw the points}
\CommentTok{# for the AZ corals}
\KeywordTok{points}\NormalTok{(}
\NormalTok{  stages}\OperatorTok{$}\NormalTok{mid[rs}\OperatorTok{$}\NormalTok{ori[groupSelector]], }
\NormalTok{  ddAZ}\OperatorTok{$}\NormalTok{oriPC[rs}\OperatorTok{$}\NormalTok{ori[groupSelector]],}
  \DataTypeTok{pch=}\DecValTok{16}\NormalTok{, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{cex=}\DecValTok{2}\NormalTok{)}
\CommentTok{# for the Z corals}
\KeywordTok{points}\NormalTok{(}
\NormalTok{  stages}\OperatorTok{$}\NormalTok{mid[rs}\OperatorTok{$}\NormalTok{ori[}\OperatorTok{!}\NormalTok{groupSelector]], }
\NormalTok{  ddZ}\OperatorTok{$}\NormalTok{oriPC[rs}\OperatorTok{$}\NormalTok{ori[}\OperatorTok{!}\NormalTok{groupSelector]],}
  \DataTypeTok{pch=}\DecValTok{16}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{cex=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/selDotShow-1.pdf} The
\texttt{combine} method will enforce both schemes for testing, but with
the default alpha levels, the binomial test would not limit the set of
selective intervals further than the one base on \texttt{AIC}.

Naturally the \texttt{ratesplit()} function can return the
\emph{p}-values of the binomial tests and the Akaike weights by setting
the \texttt{output} argument to \texttt{"full"} .

\hypertarget{slicing}{%
\subsection{4.3. Slicing}\label{slicing}}

The term slicing refers to the discretization of continuous time. The
added option to use a time variable that contains real values allows
users to use different data to express the passing of time. This
addition enables the application of the basic function to examples of
high temporal resolution, where time is close to continuous, or samples
in measured sections where it is expressed by meters within the section.

\hypertarget{unique-bin-values}{%
\subsubsection{4.3.1. Unique bin values}\label{unique-bin-values}}

In the case of the coral dataset, we can try this numerical binning
approach by assigning the estimated age mid points to the occurrences.
This is a very `dirty' way of treating occurrence data as the assumed
uncertainty of the age estimate is practically reduced to 0, and
overlapping intervals that express uncertainty will have different

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils}\OperatorTok{$}\NormalTok{mid_ma<-}\StringTok{ }\KeywordTok{apply}\NormalTok{(fossils[,}\KeywordTok{c}\NormalTok{(}\StringTok{"max_ma"}\NormalTok{,}\StringTok{"min_ma"}\NormalTok{)], }\DecValTok{1}\NormalTok{, mean)}
\end{Highlighting}
\end{Shaded}

If this column is set as the \texttt{bin} argument, than occurrences
will be treated to represent the same time interval that have the same
value in this column. The entries will be ordered by the function, but,
beware, that in physical systems time flows from smaller values to
larger values. This means that the ages estimates have to be inversed
additively, otherwise extinctions become originations and vice versa.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils}\OperatorTok{$}\NormalTok{mid_ma<-}\StringTok{ }\OperatorTok{-}\StringTok{ }\NormalTok{fossils}\OperatorTok{$}\NormalTok{mid_ma }
\end{Highlighting}
\end{Shaded}

Now the variable is ready to be used by the \texttt{divDyn()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ddIDbin <-}\StringTok{ }\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid_ma"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Please note that this is example is for illustration purposes only. As
there are too many unique entries in this \texttt{bin} variable, with
the corals, this resolution will be too high to produce potentially
meaningful patterns. Range-through diversities are possibly to closest
to reality with this method. With this type of binning, the \texttt{bin}
variable of the \texttt{divDyn} output contains the ages for the bins,
which you can use for plotting (beware the negative values, plotting
requires positive ones!)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"extinction rates"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{300}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(}\OperatorTok{-}\NormalTok{ddIDbin}\OperatorTok{$}\NormalTok{bin, ddIDbin}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"unique mid entries"}\NormalTok{,  }\StringTok{"}\CharTok{\textbackslash{}'}\StringTok{slc}\CharTok{\textbackslash{}'}\StringTok{ stages"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddBasic-1.pdf}

\hypertarget{real-numbers-sliced-bins}{%
\subsubsection{4.3.2. Real numbers, sliced
bins}\label{real-numbers-sliced-bins}}

A potentially more promising solution is to assign the occurrences that
go along a continuous time scale to regularly spaced bins. To achieve
this discretization, you have to supply a numeric vector to the
\texttt{breaks} argument of the \texttt{divDyn()} function. The entries
in this vector will represent the breakpoints or boundaries of the
interval, similarly to the \texttt{breaks} argument of the
\texttt{cut()} or \texttt{hist()} function in the base R distribution.
For the sake of simplicity, let's try a 10 million year bin resolution.
Keep in mind that the ages are still negative values!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# resolve time}
\NormalTok{  breakPoints <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\DecValTok{270}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\CommentTok{# and calculate diversity dynamics}
\NormalTok{  ddMid10<-}\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid_ma"}\NormalTok{, }\DataTypeTok{breaks=}\NormalTok{breakPoints )}
\end{Highlighting}
\end{Shaded}

In this case, the \texttt{bin} variable of the output will contain the
mid ages of the bins. Do not worry about setting the exact values for
the start and end of the age ranges. If no data occurs in the outlined
bins, then the corresponding rows in the table will be empty.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# lines  }
\KeywordTok{lines}\NormalTok{(}\OperatorTok{-}\NormalTok{ddMid10}\OperatorTok{$}\NormalTok{bin, ddMid10}\OperatorTok{$}\NormalTok{divRT, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# new legend}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"age estimates, 10MY"}\NormalTok{,  }
  \StringTok{"}\CharTok{\textbackslash{}'}\StringTok{slc}\CharTok{\textbackslash{}'}\StringTok{ stages"}\NormalTok{, }\StringTok{"unique mid entries"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{, }\StringTok{"black"}\NormalTok{),}
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/dd10actual-1.pdf} This is
fairly close to the stratigraphically constrained time series.

\hypertarget{sampling-standardization}{%
\section{5. Sampling standardization}\label{sampling-standardization}}

\hypertarget{concepts}{%
\subsection{5.1. Concepts}\label{concepts}}

\hypertarget{the-goal-of-sampling-standardization}{%
\subsubsection{5.1.1. The goal of sampling
standardization}\label{the-goal-of-sampling-standardization}}

Raw patterns of biodiversity are biased by heterogeneous, incomplete
sampling. Consider the built-in example of the coral subset, where both
the number of occurrences and the number of collections vary drastically
over time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sam <-}\KeywordTok{sampstat}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{duplicates=}\NormalTok{F)}
\KeywordTok{cor.test}\NormalTok{(dd}\OperatorTok{$}\NormalTok{divRT, sam}\OperatorTok{$}\NormalTok{occs, }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in cor.test.default(dd$divRT, sam$occs, method = "spearman"):
## Cannot compute exact p-value with ties
\end{verbatim}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  dd$divRT and sam$occs
## S = 2028.5, p-value = 3.898e-11
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.8233039
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor.test}\NormalTok{(dd}\OperatorTok{$}\NormalTok{divSIB, sam}\OperatorTok{$}\NormalTok{occs, }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in cor.test.default(dd$divSIB, sam$occs, method = "spearman"):
## Cannot compute exact p-value with ties
\end{verbatim}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  dd$divSIB and sam$occs
## S = 2.5491e-12, p-value < 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
## rho 
##   1
\end{verbatim}

Sampling standardization allows the researcher to answer the question:
would the patterns change, if sampling was homogeneous over time? There
are two ways to answer this question: extrapolation and interpolation.
Extrapolation methods try to infer on information we do not have.
Interpolation methods, on the other hand, omit information to make
sampling intensity comparable. The latter are more frequently employed
in the paleontological context, and is usually referred to as
`subsampling', while the former has more robust applications when
sampling is already quite extensive. Beware: as subsampling omits
information, the result gained by subsampling is not an unequivocal
substitute to the raw patterns, but rather their confirmation!

\hypertarget{the-formal-representation-of-subsampling}{%
\subsubsection{5.1.2. The formal representation of
subsampling}\label{the-formal-representation-of-subsampling}}

Although rarefaction is defined as a deterministic estimator, due to the
advancement of computational speed, recent implementations of the
process use Monte Carlo estimation to get expected results of the
subsampling procedure. This just means that a random subset is taken of
the given size is taken from the data, the desired statistic
(e.g.~taxonomic richness) is calculated, and these steps are iterated.
The omission of information effectively simulates lower levels of
sampling (but conditioned on the realized sampling).

This general question `what the pattern would be like?' is not specific
to estimators of richness, but is generalizable to all other statistics
that depend on sampling intensity. If the result of this estimator is
dependent on the information from the time slice, it is essentially just
a function \emph{f} of the data at hand with potential additional
arguments \emph{argF}:

\[Res= f(D, argF).\]

The same metric can be calculated with using the subsampled data in the
time slice, but first we have calculate this set with the subsampling
procedure. This is just another function g that outputs a subset of the
input dataset, to which we will refer to as the `trial dataset':

\[sub = g(D, argD)\]

Therefore, the metric in question in a trial is dependent on both the
two functions and their additional arguments. We can generalize such an
implementation of subsampling with the following notation:

\[f(g(D, argG), argF)\]

resulting in the \emph{trial result}. However this only applies to
simple estimates that only use information from a single bin
(e.g.~simple diversity metrics such as SIB). But most other metrics are
dependent on multiple slices, which means that function result can be
formalized as

\[res = f(D1, D2,â€¦. Dn, argF).\]

In order to make sampling standardization work, the subsampling
procedure has to be applied to every bin-specific datasets. This means
that a single trial result will be

\[tri = f(g(D1, argG), g(D2, argG),â€¦., g(Di, argG), argF) \]

As the trial result is the manifestation of the randomness in procedure
g it has to be recalculated iteratively. In order to extract the
expectation of this procedure, the results will also have to be averaged
in some way, both of which are implemented in the \texttt{subsample()}
function. With this notation, the function f is the \emph{applied
function} which can be specified with the \texttt{FUN} argument, the g
is the \emph{subsampler} function, which includes predefined procedures
(will be expanded so that the users can write custom procedures). The
arguments \emph{argF} and \emph{argG} are the \emph{applied} and
\emph{subsampling arguments} respectively. Naturally, you can use the
function with different instances that have the same abstract
representation. The basic arguments of subsampling are discussed in the
next chapter.

\hypertarget{basic-arguments}{%
\subsection{5.2. Basic arguments}\label{basic-arguments}}

Some arguments must be provided in order to make the function run. These
will be demonstrated with the simplest, Classical Rarefaction method
(CR, Raup, 1975). All other subsampling methods (see section `5.4.
Different Subsampling Types) use these input parameters, but most of
them will require additional arguments. In all cases, you will have to
specify the input dataset, the column containing the categories (taxon
names) and the variable of the bins, by which the data will be dissected
to run the subsampler function. These are the \texttt{dat},
\texttt{tax}, and \texttt{bin} arguments, respectively. As the function
is expected to be used on Paleobiology Database data, the duplicates
argument (see section below on this argument) is set to \texttt{FALSE}
by default for quicker use in these cases. This necessitates the 'coll'
argument that defines the column name of the collection identifiers,
which is set to the database default \texttt{collection\_no}. This
variable designates samples in the occurrence dataset. If you do not
have such samples, then setting the duplicates argument to TRUE, which
makes it possible to run the function without such a variable.

\hypertarget{subsampling-level}{%
\subsubsection{5.2.1. Subsampling level}\label{subsampling-level}}

The only other mandatory input is the `level' of subsampling, which can
be specified using the \texttt{q} argument. The exact nature of this
value is dependent on the subsampler function (see section `Different
Subsampling Methods'), but in general it expresses sampling intensity.
For the CR subsampling method, this argument represents the subsampling
quota, the desired number of occurrences in the `trial datasets'. The
`q' argument cannot be negative, and it is positively correlated with
sampling intensity (higher values mean more sampling). Increasing values
will result in increasingly higher diversities. With the subsampling
quota of 40 and 60 occurrences the function outputs the following
results for the coral dataset:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"SIB diversity"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{200}\NormalTok{))}
\CommentTok{# raw diversity}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# subsampling}
  \CommentTok{# with 40 occs.}
\NormalTok{  subCR40 <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subCR40}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \CommentTok{# with 80 occs.}
\NormalTok{  subCR80 <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subCR80}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}

\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"raw"}\NormalTok{, }\StringTok{"CR, q = 40"}\NormalTok{,}\StringTok{"CR, q = 80"}\NormalTok{),}
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddCRBasic-1.pdf}

\hypertarget{the-number-of-iterationstrials}{%
\subsubsection{5.2.2. The number of
iterations/trials}\label{the-number-of-iterationstrials}}

The precision of the simulations can be chosen by changing the number of
iterations the function will run. This can set with the \texttt{iter}
argument that has to be a single positive integer. In general, the more
iterations, the better the results, but the time the function needs to
run has a linear relationship with the iteration number. Most
paleontological examples are stable after a couple hundred iterations.
However, if the result of the function changes with every run, you will
have to increase this number!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"genus richness (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{200}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## subsampled, stable  }
\NormalTok{  subStab <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{30}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subStab}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## subsampled, unstable  }
\NormalTok{  subInstab <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{5}\NormalTok{, }\DataTypeTok{q=}\DecValTok{30}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subInstab}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"raw"}\NormalTok{, }\StringTok{"CR â€“ 30, stable"}\NormalTok{,}
    \StringTok{"CR â€“ 30, unstable"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subIter-1.pdf}

In this example, the red line is based on only 5 iterations, while the
blue one is based on 100. This typically means that the low iteration
number will have similar trajectory to the other series, but will have
more volatility due to the random sampling error. \#\#\# 5.2.3. The
\texttt{duplicates} argument In the Paleobiology Database, occurrences
are organized in collections, and are recorded as lists of taxa. These
entries optimally are on the species-level of taxonomic resolution while
most analyses operate at the level of genera. As multiple species can be
registered in a single collection, the same genus name can appear
multiple time in the collection list. This will have an effect on the
occurrence-based subsampling methods. Using the \texttt{duplicates}
arguments, you can toggle whether the surplus entries should be omitted
(\texttt{duplicates=FALSE}, default) or whether they should be kept
(\texttt{duplicates=TRUE}). The omission is applied to the variables
defined in \texttt{tax} and \texttt{coll} variables. In case
\texttt{duplicates=FALSE} the \texttt{coll} argument is mandatory.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## subsampled, stable  }
\NormalTok{  subCRnd <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subCR40}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subCRnd}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR â€“ 40 (with duplicates)"}\NormalTok{,}
    \StringTok{"CR â€“ 40"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subDupl-1.pdf} This
particular dataset actually contains multiple genus occurrences, so
changing this argument to \texttt{FALSE} is justified. However, as it
lengthens the function call considerably, so the following examples will
be based on data that already had this filtering step:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# indicate identical collection/genus combinations}
\NormalTok{collGenus <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(fossils}\OperatorTok{$}\NormalTok{collection_no, fossils}\OperatorTok{$}\NormalTok{genus)}
\CommentTok{# omit the duplicates from the occurrence datasets}
\NormalTok{fossGen <-}\StringTok{ }\NormalTok{fossils[}\OperatorTok{!}\KeywordTok{duplicated}\NormalTok{(collGenus),]}
\end{Highlighting}
\end{Shaded}

Just remember that this step can be skipped by adding
\texttt{duplicates=FALSE} to the \texttt{subsample()} function call.

\hypertarget{the-usefailed-argument}{%
\subsubsection{\texorpdfstring{5.2.4. The \texttt{useFailed}
argument}{5.2.4. The useFailed argument}}\label{the-usefailed-argument}}

The subsampling level can be set as high as the user wants it to be.
Depending on whether the data in the time slices reach the subsampling
quota or not, the time slices can be included or excluded from the
results. If the \texttt{useFailed} argument is set to \texttt{FALSE},
then the time slices that do not have enough information to reach the
subsampling quota will be omitted from the resulting series. This is the
default setting, and if the \emph{applied function} output is a scalar
or a vector, then the corresponding results will be omitted. If
\texttt{useFailed=TRUE} than the bins where the quota is not reached
will be represented in the \emph{trial dataset} with all their sampled
occurrences.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\CommentTok{# subsampled, without failed  }
\NormalTok{  withoutFail<-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{, }\DataTypeTok{useFailed=}\OtherTok{FALSE}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], withoutFail}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# subsampled, with failed }
\NormalTok{  withFail <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{, }\DataTypeTok{useFailed=}\OtherTok{TRUE}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], withFail}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR â€“ 80 occs., without failed"}\NormalTok{,}
    \StringTok{"CR â€“ 100 occs., with failed"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subFail-1.pdf}

\hypertarget{the-keep-and-remarguments}{%
\subsubsection{\texorpdfstring{5.2.5. The \texttt{keep} and
\texttt{rem}arguments}{5.2.5. The keep and remarguments}}\label{the-keep-and-remarguments}}

These arguments handle which bins should be forced to be included or
excluded from the \emph{trial dataset}. It accepts a numeric vector,
with the bin identifiers. Positive entries mean that the bins will be
included in the \emph{trial dataset} without subsampling. Negative
entries mean that the bins will be excluded from the \emph{trial
dataset}. This can be useful if one the inclusion of recent
`occurrences' to demonstrate the `Pull of the Recent' effect. This
example uses the original \texttt{corals} dataset to demonstrate how the
argument works (with duplicates omitted).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"per capita extinction rates"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\NormalTok{## subsampled, excluding the recent occurrences  }
\NormalTok{  sub <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }
    \DataTypeTok{q=}\DecValTok{50}\NormalTok{, }\DataTypeTok{rem=} \DecValTok{95}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sub}\OperatorTok{$}\NormalTok{extPC, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## subsampled, including the recent}
\NormalTok{  subPR <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }
    \DataTypeTok{q=}\DecValTok{50}\NormalTok{, }\DataTypeTok{keep=} \DecValTok{95}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid, subPR}\OperatorTok{$}\NormalTok{extPC, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"only fossils"}\NormalTok{, }
    \StringTok{"including the recent}\CharTok{\textbackslash{}n}\StringTok{(not subsampled)"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{),}
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subIntact-1.pdf}

Between these two curves, neither shows perfectly accurate results. The
per capita rates employ the range-through assumption. The first results
(\texttt{sub}) is biased by edge effects, the closer the end of the time
series is, the higher the rate values are due to decreasing amount of
total extensions. The inclusion of entries in the second dataset on the
other hand makes the `Pull of the Recent' to depress the extinction
rates of the Late Cenozoic.

\hypertarget{subsampling-output-and-plotting-options}{%
\subsubsection{5.2.6. Subsampling `output' and plotting
options}\label{subsampling-output-and-plotting-options}}

The output type of the subsampling process can be set with the output
argument. This should be dependent the further use of the function
results. The most direct output is the arithmetic (default) or geometric
means of the trials. They provide almost the same output:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\NormalTok{## arithmetic mean output}
\NormalTok{  subArit <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{output=}\StringTok{"arit"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subArit}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## geometric mean output  }
\NormalTok{  subGeom <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{output=}\StringTok{"geom"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subGeom}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"arithmetic means"}\NormalTok{, }\StringTok{"geometric means"}\NormalTok{),}
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subOutput-1.pdf}

However, subsampling output demonstrates the natural variance arising
from the simulating nature of the process. The results of the individual
trials can be conserved by setting the output argument to either
\texttt{"dist"} or \texttt{"list"}. The difference between these two
options is that \texttt{dist} groups the results of the trials by the
structure of the original function. In the cases when the
\texttt{divDyn()} function being the \emph{applied function} (every
examples until now), the output is a list, where all variables are
matrices.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## subsampled, dist output }
\NormalTok{  subDist <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{output=}\StringTok{"dist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the variables}
\KeywordTok{names}\NormalTok{(subDist)}
\CommentTok{# the dimensions of a single variable}
\KeywordTok{dim}\NormalTok{(subDist}\OperatorTok{$}\NormalTok{divCSIB)}
\end{Highlighting}
\end{Shaded}

Rows are time slices, while columns represent the individual trials.
These can be visualized by a simple \texttt{for()} loop, and the
arithmetic means can be calculated the regular way.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"subsampled richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{))}

\NormalTok{plottedVar <-}\StringTok{ }\NormalTok{subDist}\OperatorTok{$}\NormalTok{divCSIB}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(plottedVar))\{}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], plottedVar[,i], }\DataTypeTok{col=}\StringTok{"#00000099"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\CommentTok{# the mean}
\NormalTok{csibMeans<-}\StringTok{ }\KeywordTok{apply}\NormalTok{(plottedVar,}\DecValTok{1}\NormalTok{, mean, }\DataTypeTok{na.rm=}\NormalTok{T)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], csibMeans , }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subMultiRes-1.pdf}

For convenience, this variance can also be plotted with the new
\texttt{shades()} function. That will display the distribution of values
by drawing transparent polygons. The quantiles of each distribution is
calculated, and the same values are then connected (.75 to .75).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"subsampled richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{))}
\KeywordTok{shades}\NormalTok{ (stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], plottedVar, }\DataTypeTok{res=}\DecValTok{10}\NormalTok{, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/shades-1.pdf}

Setting the \texttt{res} argument of this function controls the
`quantile resolution'. The higher the number, the more refined the
transparency gradient will be. Beware that setting this value too high
will make the figure look somewhat `psychedelic'

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"subsampled richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{))}
\KeywordTok{shades}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], plottedVar, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{res=}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/shades100-1.pdf}

The function's color argument only accepts colors that are specified
without the alpha channel (for instance no \texttt{"\#00000066"} is
impossible, but \texttt{"blue"} or \texttt{"\#4433FF"} are perfectly
viable).

\hypertarget{the-applied-function-during-the-subsampling}{%
\subsection{5.3. The applied function during the
subsampling}\label{the-applied-function-during-the-subsampling}}

By default, executing the \texttt{subsample()} command on the occurrence
data will run the \texttt{divDyn()} function in every iteration, which
is specified by the \texttt{FUN} argument (function \emph{f} in the
notation above). Setting this argument to \texttt{NULL} will not run any
function on the subsampled data subset of the trials (\emph{trial
data}). After all iterations are finished, the data subsets will be
concatenated and the function will output them as a list of length
\texttt{iter}. This option coerces the output type of the function to
\texttt{list}, no other output type is possible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## subsampled }
\NormalTok{subData <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{,}\DataTypeTok{FUN=} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# characteristics}
\KeywordTok{class}\NormalTok{(subData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "list"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(subData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# columns of the trial dataset}
\KeywordTok{colnames}\NormalTok{(subData[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "genus"          "collection_no"  "family"         "abund_value"   
##  [5] "abund_unit"     "reference_no"   "life_habit"     "diet"          
##  [9] "country"        "geoplate"       "lat"            "lng"           
## [13] "paleolat"       "paleolng"       "period"         "epoch"         
## [17] "subepoch"       "stage"          "early_interval" "late_interval" 
## [21] "max_ma"         "min_ma"         "slc"            "Bin"           
## [25] "env"            "lith"           "latgroup"       "bath"          
## [29] "gensp"          "ecology"        "ecologyMostZ"   "ecologyMostAZ" 
## [33] "ecologyBoth"    "growth"         "integration"    "slcMid"        
## [37] "mid_ma"
\end{verbatim}

The advantage of this option is that you can inspect the results of the
subsampling output. You can also iterate a custom function on this
output by using the \texttt{lapply()} interator in base R. The results
of the function will be output as a \texttt{list}.

\hypertarget{example-1-checking-the-number-of-occurrences}{%
\subsubsection{5.3.1. Example 1: Checking the number of
occurrences}\label{example-1-checking-the-number-of-occurrences}}

One of the functions we can check is the number of occurrences in the
`trial datasets'. By the rules of CR, this should be exactly \texttt{q}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{OCC <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{table}\NormalTok{(x}\OperatorTok{$}\NormalTok{slc)}
\CommentTok{# list of trials, each contains the number of occurrences in a bin (vector)}
\NormalTok{subOccs <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(subData, OCC)}
\CommentTok{# one trial}
\NormalTok{subOccs [[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 
## 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
\end{verbatim}

Extracting the central tendency (average of the trials) is more
difficult this way, but some output structures (e.g.~geographic shapes)
might require special treatment that can be written as a custom
function. Anyway, \texttt{subsample()} allows the simplification of this
process, if you set the output argument to `list' and by providing the
custom function as the \texttt{FUN} argument. The only rule there is, is
that the function must take the occurrence dataset as an argument, which
is formally called \texttt{dat}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{OCC <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(dat) }\KeywordTok{table}\NormalTok{(dat}\OperatorTok{$}\NormalTok{slc)}
\NormalTok{subOccsInternal <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{,}\DataTypeTok{FUN=}\NormalTok{ OCC, }\DataTypeTok{output=}\StringTok{"list"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subOccsInternal[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 
## 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
\end{verbatim}

Whether averaging is possible, will be dependent on the output of the
\emph{applied function}. If the output of the vector is scalar, then the
output methods \texttt{"arit"} and \texttt{"geom"} will return a scalar,
and \texttt{"dist"} will return a vector. If the output of the function
is a vector, both \texttt{"arit"} and \texttt{"geom"} will return a
single vector, and \texttt{"dist"} will return a matrix. If the result
of the \emph{applied function} is a \texttt{data.frame}, then the result
of \texttt{"arit"} and \texttt{"geom"} will be \texttt{data.frame}s too.
In this case, if the output is \texttt{"dist"}, then the output of the
subsample function will be a \texttt{list}, each of its elements
representing one of the variables in the output of the \emph{applied
function}, but instead of containing vectors, they will contain
matrices. This is the case for the \texttt{divDyn()} function. Running
the function \texttt{OCC()} above with the \texttt{"dist"} type output
will produce a matrix of occurrences:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subDistOccs <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{,}\DataTypeTok{FUN=}\NormalTok{ OCC, }\DataTypeTok{output=}\StringTok{"dist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(subDistOccs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  int [1:41, 1:100] 40 40 40 40 40 40 40 40 40 40 ...
##  - attr(*, "dimnames")=List of 2
##   ..$ : chr [1:41] "54" "55" "56" "57" ...
##   ..$ : NULL
\end{verbatim}

Note the dimensions of the matrix, which is \texttt{41Ã—100}, the number
of sampled time slices and the number of subsampling trials. CAUTION:
The averaging and the result grouping is possible, because the
\emph{applied function} is run on the total dataset first, which will
result in a container prototype that is used to store the trial results.
If the function output structure (i.e.~dimensions) is different when it
is run for the subsets than when it is run on the total dataset, the
subsample function will output an error.

\hypertarget{example-2-maximum-absolute-paleolatitudes}{%
\subsubsection{5.3.2. Example 2: maximum absolute
paleolatitudes}\label{example-2-maximum-absolute-paleolatitudes}}

Let's say you are interested in the maximum absolute paleolatitude of
the occurrences. This will be influenced by the number of occurrences,
and should therefore be rechecked with subsampling. You can calculate
this in the raw dataset with the following function, using the known
variable names:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{PL <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(dat)\{}
\NormalTok{  tRes<-}\StringTok{ }\KeywordTok{tapply}\NormalTok{(}\DataTypeTok{INDEX=}\NormalTok{dat}\OperatorTok{$}\NormalTok{slc, }\DataTypeTok{X=}\NormalTok{dat}\OperatorTok{$}\NormalTok{paleolat, }\DataTypeTok{FUN=}\ControlFlowTok{function}\NormalTok{(y)\{}
    \KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(y), }\DataTypeTok{na.rm=}\NormalTok{T)}
\NormalTok{  \})}
\KeywordTok{return}\NormalTok{(tRes)}
\NormalTok{\}}
\NormalTok{maxPaLat<-}\StringTok{ }\KeywordTok{PL}\NormalTok{(fossils)}
\end{Highlighting}
\end{Shaded}

This variable certainly increases with age,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor.test}\NormalTok{(maxPaLat, stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{54}\OperatorTok{:}\DecValTok{94}\NormalTok{], }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  maxPaLat and stages$mid[54:94]
## S = 18336, p-value = 5.307e-05
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.5972125
\end{verbatim}

but it is questionable at this point, whether the increasing number of
occurrences is responsible for this pattern, or whether you would still
see it, if the same number of occurrences were sampled from each time
slice. You can quickly check this association at 40 occurrences and CR
by running:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subMaxPaLat <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{20}\NormalTok{,}\DataTypeTok{FUN=}\NormalTok{PL)}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"maximum sampling paleolatitude"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{54}\OperatorTok{:}\DecValTok{94}\NormalTok{], maxPaLat, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{54}\OperatorTok{:}\DecValTok{94}\NormalTok{], subMaxPaLat, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subPLSmm-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor.test}\NormalTok{(subMaxPaLat, stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{54}\OperatorTok{:}\DecValTok{94}\NormalTok{], }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{different-subsampling-types}{%
\subsection{5.4. Different subsampling
types}\label{different-subsampling-types}}

\hypertarget{classical-rarefaction-cr}{%
\subsubsection{5.4.1. Classical Rarefaction
(CR)}\label{classical-rarefaction-cr}}

Classical Rarefaction is the most straightforward subsampling method. It
is based on the assumption, that the number of occurrences is a direct
proxy for sampling intensity. Although this assumption can be criticized
(see below), the general applicability of the method, and
straightforward interpretation of the results makes it especially useful
for checking the distorting effects of sampling.

\hypertarget{occurrence-weighted-by-list-subsampling-oxw}{%
\subsubsection{\texorpdfstring{5.4.2. Occurrence-weighted by-list
subsampling
(O\textsuperscript{x}W)}{5.4.2. Occurrence-weighted by-list subsampling (OxW)}}\label{occurrence-weighted-by-list-subsampling-oxw}}

By-list subsampling methods use information about how the occurrences
are clustered in lists. In the PaleoDB, these clusters are the
collections that `contain' the occurrences, which are direct products of
sampling. Depending on whether we would like to emphasize the sampling
of collections (related to beta diversity) or the number of entries in
lists, you can use the O\textsuperscript{x}W group of subsampling. Since
the development of SQS (or CBR, see below) these methods have not been
widely applied, but nevertheless, they could be useful in some projects.
The basis of these methods is that collection integrity cannot be broken
during the subsampling procedure. Entire lists are drawn from the
subsampling pool of each time bin, while the number of occurrences are
tracked. These list are the collections that should be indicated by
setting the \texttt{coll} variable appropriately. When the quota is
reached, no more occurrences are drawn. The rest of the process
(assembly of the \emph{trial dataset}, running the \emph{applied
function}) is the same as with the CR method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subOW <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The output of the occurrence-weighted (OW) type is typically very close
to the output of the corresponding level CR results:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subCR <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{)}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB diversity"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subCR}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subOW}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR - 40"}\NormalTok{, }\StringTok{"OW - 40"}\NormalTok{), }
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subOW-1.pdf}

The reason why the method type is called the O\textsuperscript{x}W is
because depending on the relative importance of the collections and the
entries within the collection lists express different aspects of
sampling. This can be taken into consideration with the exponentiation
of the occurrence counts in each collection. The simplest way of doing
this is the raise the number of occurrences in a collection to the power
of 0, which effectively means the selection a certain number of
collections in all different time slices. Setting the \texttt{x}
argument to 0, will force this setting. This is sometimes referred to as
the `unweigthed subsampling' method. In this case the \texttt{q}
argument will represent the quota of collections.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trialsUW <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{10}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{0}\NormalTok{, }\DataTypeTok{FUN=}\NormalTok{sampstat)}
\CommentTok{# the number of sampled collections on average in each timeslice}
\NormalTok{trialsUW[}\DecValTok{54}\OperatorTok{:}\DecValTok{94}\NormalTok{, }\StringTok{"colls"}\NormalTok{]}
\NormalTok{subUW <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{10}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

By this principle, it is not difficult to see that depending on the size
of the collections, the actual number of occurrences will be somewhat
higher than the quota. You can quickly check the exact number of
occurrences drawn with the \texttt{sampstat()} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subST <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{20}\NormalTok{,}\DataTypeTok{FUN=}\NormalTok{sampstat, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subST[}\DecValTok{54}\OperatorTok{:}\DecValTok{94}\NormalTok{, }\StringTok{"occs"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 22.52 22.63 24.84 24.39 25.48 23.36 21.82 23.73 21.79 24.22 22.65
## [12] 25.99 23.11 26.50 27.08 32.09 24.14 26.12 25.37 27.21 28.66 26.26
## [23] 27.97 23.34 26.04 26.70 26.09 24.54 22.96 24.49 22.46 24.54 23.39
## [34] 27.15 26.06 25.36 28.07 23.42 24.54 25.35 24.85
\end{verbatim}

Although there are ways to improve the accuracy of the subsampling
process, the variation induced by this problem is only minuscule to
those introduced by sampling and binning uncertainties. However,
typically this \texttt{x} value is set to a value between 1 and 2
(e.g.~1.4). In these cases, you have to calculate the intensity of
sampling . Although there is some discrepancy between the methods, the
overall trajectories are quite similar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subO2W <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{2}\NormalTok{)}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB genus richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subCR}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subOW}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subUW}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], subO2W}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR - 40"}\NormalTok{, }\StringTok{"OW - 40"}\NormalTok{, }\StringTok{"UW - 10"}\NormalTok{, }\StringTok{"O2W - 80"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subO2-1.pdf}

\hypertarget{shareholder-quorum-subsampling-sqs}{%
\subsubsection{5.4.3. Shareholder Quorum Subsampling
(SQS)}\label{shareholder-quorum-subsampling-sqs}}

As intuitive the CR approach is to understand, the method has been
criticized for be being `unfair' (Alroy, 2010). The results of CR will
not reflect changes of richness appropriately, if two localities with
different diversities are compared and their total richness are not
equal. This can be visualized by progressively lowering the subsampling
quota for CR, which will result in not just decreased levels of richness
but also in a pronounced decrease in variation. This effect can be
illustrated by rerunning CR iteratively with progressively lower quotas.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# repeat CR subsampling for a set of quotas}
\NormalTok{quotas<-}\KeywordTok{seq}\NormalTok{(}\DecValTok{70}\NormalTok{,}\DecValTok{10}\NormalTok{,}\OperatorTok{-}\DecValTok{10}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in}\NormalTok{ quotas)\{}
   \CommentTok{# actual CR }
\NormalTok{   cr<-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\NormalTok{i,}\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }
    \DataTypeTok{useFailed=}\OtherTok{FALSE}\NormalTok{)}
  \CommentTok{# store output}
  \KeywordTok{assign}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"cr"}\NormalTok{, i, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{), cr)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The code above reruns the CR algorithm on the dataset with 70, 60, 50
\ldots{} and 10 occurrences as the quota of the subsampling. Then the
results can be plotted with:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in}\NormalTok{ quotas)\{}
\NormalTok{  current <-}\StringTok{ }\KeywordTok{get}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"cr"}\NormalTok{, i, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], current }\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subCRmanyShow-1.pdf}

As the subsampling quota decreases, so does the mean value of richness,
and also the relative deviation of the series. The Shareholder Quorum
subsampling approach (Alroy, 2010) effectively circumvents this problem
by using a different proxy for sampling completeness, other than the
number of occurrences. Rather than looking at the basic unary
information of occurrences, the SQS method assesses sampling with
frequency coverage. Coverage is an intuitive way to express the
completeness of sampling. In the species sampling pool all species have
a frequency (F\textsuperscript{k}) that sum up to 1. In this sense, the
coverage of a sample is the sum of species frequencies in the original
sampling pool (F\textsuperscript{k}), but only for those species that
actually have been sampled. This rule effectively coerces coverage
between 0 and 1. Different levels of sampling can be created by
maximizing the desired coverage of a sample. This desired coverage is
referred to as the `quorum'. After the work of Chao and Jost (2012),
ecologists usually refer to this approach as coverage-based rarefaction.

\hypertarget{the-inexact-approach-to-sqs}{%
\paragraph{5.4.3.1. The `inexact' approach to
SQS}\label{the-inexact-approach-to-sqs}}

The original description of the SQS algorithm ensured different levels
of coverages by going through the occurrences (or collections) randomly
and aggregating the estimated frequencies of the species that are taken
from the sample until this sum reached the subsampling quorum. John
Alroy (2014) referred to this approach as the `inexact' method to
perform SQS. This is the default way to do SQS.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# sqs with 0.6 quorum}
\NormalTok{sqs0}\FloatTok{.6}\NormalTok{ <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.6}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{,  }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{)}
\CommentTok{#sqs with 0.3 quorum}
\NormalTok{sqs0}\FloatTok{.3}\NormalTok{ <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.3}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{175}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqs0}\FloatTok{.6}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqs0}\FloatTok{.3}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], dd}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"raw"}\NormalTok{, }\StringTok{"SQS â€“ 0.6"}\NormalTok{, }\StringTok{"SQS â€“ 0.3"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs1-1.pdf} This procedure
is dependent on the proper estimation of the species' frequencies in the
sampling pool (?frequencies). Alroy (2010) suggested that the observed
frequencies should be adjusted with Good's total sample coverage
estimator \emph{u}, which is dependent on the number of occurrences
(\emph{o}) and the number of single-collection (single-occurrence) taxa
(\emph{\textsuperscript{1}O }).

\[u = 1 â€“ {1}O/o\]

This is the first correction of Alroy (2010, for overall coverage). He
also suggested that for Paleobiology Database occurrences, a different
version of this estimator (\emph{u'}) might be more accurate that
instead of counting the counts the single reference taxa, instead of
single-collection taxa. This estimator is then used to estimate the true
frequencies of species. You can choose between these versions by
toggling the \texttt{singleton} argument between \texttt{"occ"}
(default), \texttt{"ref"} and can be switched off by setting it to
\texttt{FALSE}. Note that \texttt{"ref"} will require you to provide a
reference variable (\texttt{ref} argument). The discrepancy between the
methods is very small:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsCollSing <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{, }
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }
  \DataTypeTok{singleton=}\StringTok{"occ"}\NormalTok{)}
\NormalTok{sqsRefSing <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{,}
  \DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{)}
\NormalTok{sqsNoSing <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{singleton=}\OtherTok{FALSE}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsRefSing}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsCollSing}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsNoSing}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"SQS â€“ 0.4 - NA"}\NormalTok{, }\StringTok{"SQS â€“ 0.4 - ref"}\NormalTok{, }\StringTok{"SQS â€“ 0.4 - occ"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs2-1.pdf} Alroy (2010)
also mentioned two additional corrections (for \emph{Evenness and
Dominance} and \emph{Single large collections}) that also have minor
effects on the overall results. You can us the \texttt{excludeDominant}
and \texttt{largestColl} arguments to turn these on. Note that you have
to provide a collection variable to make \texttt{largestColl} work,
which is only available if \texttt{excludeDominant=TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsPure <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.5}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{)}
\NormalTok{sqsCorr <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.5}\NormalTok{,}
 \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{,}\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
 \DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{, }\DataTypeTok{excludeDominant=}\NormalTok{T, }\DataTypeTok{largestColl=}\NormalTok{T)}

\CommentTok{# plotting}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsPure}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsCorr}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"uncorrected, inexact SQS"}\NormalTok{, }
  \StringTok{"corrected inexact SQS"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs3-1.pdf}

So far, these calculations were based on occurrence-based rarefaction,
but SQS can be calculated similarly to OW, by tallying the occurrences
collection-by-collection. This can be enforced with the
\texttt{byList=TRUE} option.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsByColl <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.5}\NormalTok{,}
 \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{,}\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
 \DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{, }\DataTypeTok{excludeDominant=}\NormalTok{T, }\DataTypeTok{largestColl=}\NormalTok{T, }\DataTypeTok{byList=}\OtherTok{TRUE}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsByColl}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsCorr}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"by-list SQS"}\NormalTok{, }
  \StringTok{"by-occurrence SQS"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqsColl-1.pdf}

\hypertarget{the-exact-approach-to-sqs}{%
\paragraph{5.4.3.3. The 'exact approach to
SQS}\label{the-exact-approach-to-sqs}}

The `exact' method (Alroy, 2014), is much easier to comprehend. The
procedure is similar to CR and in a sense that the occurrences are
sampled one-by-one from the sampling pool. The difference is however,
that the sampling level is not approximated by the number of occurrences
in the subset, but the directly estimated coverage with (Good's \emph{u}
or Alroy's \emph{u'}). The algorithm calculates coverage for shuffled
sets of occurrences between 1 occurrence and all occurrences. As the
number of occurrences increase, the estimated coverage will increase,
but not monotonically, and will cross the level of the desired quorum
multiple times. These occurrence numbers are registered and their
medians will be taken as the solution of the algorithm. As coverage is
estimated millions of times, this approach is computationally more
intensive than the `inexact' approach.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsExact <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{30}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{, }\DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{,}
  \DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{vers=}\StringTok{"exact"}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{plotTS}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\OperatorTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsExact}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages}\OperatorTok{$}\NormalTok{mid[}\DecValTok{1}\OperatorTok{:}\DecValTok{94}\NormalTok{], sqsPure}\OperatorTok{$}\NormalTok{divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"uncorrected, inexact SQS"}\NormalTok{, }
  \StringTok{"exact SQS"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs4-1.pdf} The
\texttt{singleton} argument is also implemented for the exact approach,
although it has to be either \texttt{"occ"} or \texttt{"ref"} otherwise
the function will not run.

\hypertarget{concluding-remarks-on-sqs}{%
\paragraph{5.4.3.3. Concluding remarks on
SQS}\label{concluding-remarks-on-sqs}}

SQS is probably the most appropriate method we have today for sampling
standardization of diversity curves. Although the number of potential
influencing factors is high, they do not influence the overall
trajectory of the curves, and the induced variation is almost equal to
the variability that is created by subsampling itself (plot some results
with \texttt{output="dist"}). The systematical evaluation of these
options is still lacking, but we are working on the appropriate testing
framework.

\hypertarget{environmental-affinities}{%
\section{6. Environmental affinities}\label{environmental-affinities}}

Most taxa prefer certain environments. Our understanding of
environmental affinities of different taxa depend on the characteristics
of sampling. In most questions the definition of two environments
suffices, and most hypotheses can be tested with univariate statistics
between two samples. Using the most basic logic, one could infer that a
taxon preferred environment \emph{A} to environment \emph{B}, if it
occurs more in that particular environment over its lifetime. This is
sometimes referred to as the majority rule of affinity, and is very
straightforward to implement. In our test example, a number of variables
are added based on the raw data, which express the environmental
conditions of the dataset. For the sake of demonstration, the
bathymetric affinities \texttt{bath} will be calculated. First, we have
to omit those occurrences that have unknown depth conditions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knownBath <-}\StringTok{ }\NormalTok{fossils[fossils}\OperatorTok{$}\NormalTok{bath}\OperatorTok{!=}\StringTok{"uk"}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\hypertarget{majority-rule}{%
\subsection{6.1. Majority rule}\label{majority-rule}}

After this simple filtering, the \texttt{affinity()} function can be
applied to the dataset, with specifying the usual arguments, plus the
\texttt{"majority"} method. The function also needs to be noted about
the column (its name. \texttt{env="bath"} in our case) that contains the
environmental variable in question:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affMajor <-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"majority"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affMajor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affMajor
## deep shal 
##   25  693
\end{verbatim}

The output of this function is a single character vector, values
specifying the preferred environments and the \texttt{names} attribute
defining the taxon names. \texttt{NA} entries occur when the function is
unable to define an affinity (i.e.~the number of occurrences from both
environments is the same). As you can see, an overwhelming majority of
the taxa has shallow affinities based on this method, but this is not
surprising, as most of the occurrences actually come from shallow
environments.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(knownBath}\OperatorTok{$}\NormalTok{bath)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  deep  shal 
##  1035 25644
\end{verbatim}

\hypertarget{binomial-method}{%
\subsection{6.2. Binomial method}\label{binomial-method}}

If sampling is so dominated by shallow occurrences, then the obvious
question that arises is whether the apparent pattern of affinity only is
present because this biased sampling. In order to correct for this
`background' sampling issue, Foote (2006) suggested that the environment
affinity should be determined by comparing the taxon's observed pattern
of occurrences to that present in the total dataset (null sampling
probability of the environment). This approach was also used by
Kiessling and Aberhan (2007) and Kiessling and Kocsis (2015) in later
studies. The sampling probability of the environment is calculated by
taking the proportion of occurrences in the two environments in the
total dataset from the range of the taxon. Under random sampling
conditions, the number of total occurrences and the number among these
that come from an environment is modelled by a binomial distribution.
Given a certain level of confidence one guess whether the sampled
occurrences of at taxon represent a significantly higher or lower
proportion than predicted by the null probability. The more likely it is
that a simple binomial model can produce the observed success/total
trial ratio, the less we know about the affinity of the taxon. This
approach is implemented by the default \texttt{"binom"} method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affBin1 <-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affBin1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affBin1
## deep shal 
##  135  574
\end{verbatim}

The significance of the binomial tests can be chosen by the
\texttt{alpha} argument that toggles the breadth of proportions that is
considered to be output by the randomness of sampling. The default
\texttt{alpha\ =\ 1} setting (above) will not perform the binomial test.
It will only compare the taxon's observed proportion of occurrences from
the different environments to those observed in the total dataset. The
lower this \texttt{alpha} value is, the less taxa will get an assigned
affinity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affBin0}\FloatTok{.5}\NormalTok{ <-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affBin0}\FloatTok{.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affBin0.5
## deep shal 
##  127  149
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affBin0}\FloatTok{.1}\NormalTok{ <-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"slc"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.1}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affBin0}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affBin0.1
## deep shal 
##   77   56
\end{verbatim}

Using the standard 95\% percent as alpha level is an arbitrary choice.
As the fossil record has quality issues, a 90\% confidence
(\texttt{alpha\ =\ 0.1}) is preferred in most cases.

\hypertarget{acknowledgements}{%
\section{Acknowledgements}\label{acknowledgements}}

The package was developed in the context of a project on global
paleobiogeography funded by the Deutsche Forschungsgemeinschaft (DFG
project numbers Ko 5382/1-1 and Ko 5382/1-2). The package is also part
of the DFG Research Unit 2332: TERSANE (TEmperature Related Stressors in
Ancient Extinctions). We are thankful to all testers of the package,
including Emilia Jarochowska, Vanessa Roden, Andreas Lauchstedt, and all
participants of the first year International Master's Programme for
Paleobiology at the GeoZentrum Nordbayern, FAU in Erlangen, Germany. We
thank all enterers of the Paleobiology Database.

\hypertarget{references}{%
\section{References}\label{references}}

Alroy, J. (2008). Dynamics of origination and extinction in the marine
fossil record. Proceedings of the National Academy of Science, 105,
11536â€``11542.

Alroy, J., Aberhan, M., Bottjer, D. J., Foote, M., FÃ¼rsich, F. T.,
Harries, P. J., â€¦ Visaggi, C. C. (2008). Phanerozoic Trends in the
Global Diversity of Marine Invertebrates. Science, 321(5885), 97â€``100.
\url{https://doi.org/10.1126/science.1156963}

Alroy, J. (2010). The Shifting Balance of Diversity Among Major Marine
Animal Groups. Science, 329, 1191â€``1194.
\url{https://doi.org/10.1126/science.1189910}

Alroy, J. (2014). Accurate and precise estimates of origination and
extinction rates. Paleobiology, 40(3), 374â€``397.
\url{https://doi.org/10.1666/13036}

Alroy, J. (2015). A more precise speciation and extinction rate
estimator. Paleobiology, 41(04), 633â€``639.
\url{https://doi.org/10.1017/pab.2015.26}

Bell, M. A. (2015). geoscale: Geological Time Scale Plotting. R package
version 2.0. Retrieved from
\url{http://CRAN.R-project.org/package=geoscale}

Foote, M., \& Raup, D. M. (1996). Fossil Preservation and the
Stratigraphic Ranges of Taxa. Paleobiology, 22(2), 121â€``140.

Chao, A., \& Jost, L. (2012). Coverage-based rarefaction and
extrapolation: standardizing samples by completeness rather than size.
Ecology, 93(12), 2533â€``2547. \url{https://doi.org/10.1890/11-1952.1}

Foote, M. (2000). Origination and Extinction Components of Taxonomic
Diversity: General Problems. Paleobiology, 26(4), 74â€``102.

Foote, M. (2006). Substrate Affinity and Diversity Dynamics of Paleozoic
Marine Animals. Paleobiology, 32(3), 345â€``366.
\url{https://doi.org/10.2307/4096955}

Good, I. J. (1953). The Popoulation Frequencies of Species and the
Estimation of Population Parameters. Biometrika, 40(3/4), 237â€``264.

Gradstein, F. M., Ogg, J. G., \& Schmitz, M. (2012). The Geologic Time
Scale 2012. Elsevier Science \& Technology Books.

Kiessling, W., \& Aberhan, M. (2007). Environmental determinants of
marine benthic biodiversity dynamics through Triassic-Jurassic time.
Paleobiology, 33(3), 414â€``434.

Kiessling, W., \& Kocsis, A. T. (2015). Biodiversity dynamics and
environmental occupancy of fossil azooxanthellate and zooxanthellate
scleractinian corals. Paleobiology, 41(3), 402â€``414.

Kiessling, W., \& Simpson, C. (2011). On the potential for ocean
acidification to be a general cause of ancient reef crises. Global
Change Biology, 17, 56â€``67.
\url{https://doi.org/10.1111/j.1365-2486.2010.02204.x}

Raup, D. M. (1975). Taxonomic Diversity Estimation Using Rarefaction.
Paleobiology, 1, 333â€``342. \url{https://doi.org/10.2307/2400135}

Raup, D. M. (1979). Biases in the fossil record of species and genera.
Bulletin of the Carnegie Museum of Natural History, 13, 85-91.

Raup, D. M. (1985). Mathematical Models of Cladogenesis. Paleobiology,
11(1), 42â€``52.

Sepkoski Jr, J. J. (2002). A compendium of fossil marine animal genera.
Bulletins of American paleontology, 363, 1-560.


\end{document}
